---
title: 'Getting Started with Prometheus Remote Write Exporter for AMP'
description:
    In this Getting Started guide, we’ll show you how to configure the ADOT Collector to scrape from a Prometheus-instrumented application, 
    and send metrics to AWS Managed Service for Prometheus (AMP).
path: '/docs/getting-started/prometheus-remote-write-exporter'
---

import SectionSeparator from "components/MdxSectionSeparator/sectionSeparator.jsx"
import SubSectionSeparator from "components/MdxSubSectionSeparator/subsectionSeparator.jsx"
import prometheusPipelineEKSImg from "assets/img/docs/gettingStarted/prometheus/eks/Prometheus_Pipeline.png"
import proxyIngestRoleEKSImg from "assets/img/docs/gettingStarted/prometheus/eks/IAMProxyIngestRole.png"
import proxyIngestRoleTrustRelationshipEKSImg from "assets/img/docs/gettingStarted/prometheus/eks/IAMProxyIngestRole_TrustRelationship.png"
import proxyIngestRolePoliciesEKSImg from "assets/img/docs/gettingStarted/prometheus/eks/IAMProxyIngestRole_Policies.png"
import prometheusPipelineECSImg from "assets/img/docs/gettingStarted/prometheus/ecs/Prometheus_Pipeline.png"
import createClusterECSImg from "assets/img/docs/gettingStarted/prometheus/ecs/CreateCluster.png"
import availableMetricsECSImg from "assets/img/docs/gettingStarted/prometheus/ecs/AvailableMetrics.png"

In order to scrape and export metrics to your AWS Managed Service for Prometheus (AMP) instance, you can use either the AWS Distro for 
the OpenTelemetry Collector (ADOT Collector) or a standard vanilla Prometheus server.

In this Getting Started guide, we’ll show you how to configure the ADOT Collector to scrape from a Prometheus-instrumented application, 
and send metrics to the AWS Managed Service for Prometheus (AMP).

<SectionSeparator />

## Before you Begin

The ADOT-AMP pipeline enables us to use the ADOT Collector to scrape a Prometheus-instrumented application, and send the scraped metrics 
to AWS Managed Service for Prometheus (AMP). 

<img src={prometheusPipelineEKSImg} alt="Diagram" style="margin: 30px 0;" />

The ADOT-AMP pipeline includes two OpenTelemetry Collector components specific to Prometheus — the Prometheus Receiver and the AWS Prometheus 
Remote Write Exporter. 

<SectionSeparator />

## Service Discovery 

The Prometheus Receiver can be configured using your existing 
[Prometheus configurations](https://prometheus.io/docs/prometheus/latest/configuration/configuration/) to perform service discovery and metric 
scraping. There are many possible configurations to discover monitored targets including Kubernetes service discovery (kubernetes_sd_config)
 and static hosts (static_config). Note that the Prometheus Receiver will scrape metrics in the Prometheus exposition format. Any applications 
 or endpoints that you want to scrape should be configured with the Prometheus client library.

The AWS Prometheus Remote Write Exporter will use the remote_write endpoint to send the scraped metrics to an AMP instance. The HTTPs requests 
used to export data will be signed with [AWS SigV4](https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html), AWS’ 
authentication protocol for secure authentication.

<SectionSeparator />

## Basic Kubernetes/EKS Configuration for AMP

Now, we'll enable Prometheus collection on an EKS cluster. In this scenario, we will use the Prometheus Receiver to perform service discovery in 
an EKS cluster and metric scraping. We will scrape from an application that provides us with some example Prometheus metrics. Notice that this setup 
will also work for an on-premise Kubernetes configuration.

For information about advanced configurations and how to scrape Kubernetes infrastructure with the ADOT Collector-AMP pipeline, please take a look 
[here](/docs/getting-started/advanced-prometheus-remote-write-configurations)

<SubSectionSeparator />

### Prerequisites

Before getting started, you will need to set up the following components:

* An AMP workspace should be set up. Guides for this can be found [here](https://docs.aws.amazon.com/prometheus/latest/userguide/what-is-Amazon-Managed-Service-Prometheus.html). 
* A Kubernetes or EKS cluster. The EKS cluster can be on either EC2 or Fargate. If you need to set up an EKS cluster, please use the following [guide](https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html). 
You can check the name of the active context/cluster using this command `kubectl config current-context`.
* If you are setting up the ADOT Collector of AWS EKS, you will need to [set up IAM roles for service accounts for the ingestion of metrics from Amazon EKS clusters](https://docs.aws.amazon.com/prometheus/latest/userguide/set-up-irsa.html#set-up-irsa-ingest). 
Please follow the **To set up IRSA for ingestion into AMP** section. This section will create a IAM role for the service account that we will use for the 
ADOT Collector to scrape and export metrics.

<SubSectionSeparator />

### Editing the Trust Policy 

If you are setting up the ADOT Collector of AWS EKS, you will need to edit the trust policy created in the prerequisites.

1. Go to your IAM Management Console to find the **amp-iamproxy-ingest-role** that was created in the prerequisites. 

<img src={proxyIngestRoleEKSImg} alt="Diagram" style="margin: 30px 0;" />

2. Go to trust relationships and click **Edit trust relationship.**

<img src={proxyIngestRoleTrustRelationshipEKSImg} alt="Diagram" style="margin: 30px 0;" />

3. Then, replace the **aws-amp** namespace for the service account to **adot-col**. Your resulting trust policy should reflect the example below:

```json lineNumbers=true 
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Federated": "arn:aws:iam::account-id:oidc-provider/oidc.eks.aws_region.amazonaws.com/id/openid"
      },
      "Action": "sts:AssumeRoleWithWebIdentity",
      "Condition": {
        "StringEquals": {
          "oidc.eks.aws_region.amazonaws.com/id/openid:sub": "system:serviceaccount:adot-col:amp-iamproxy-ingest-service-account"
        }
      }
    }
  ]
}
```

4. Please make sure the following permissions policy is attached to the IAM role above:

<img src={proxyIngestRolePoliciesEKSImg} alt="Diagram" style="margin: 30px 0;" />


<SubSectionSeparator />

### Sample App

We will be using a simple sample app that is used for the integration tests of this pipeline. You can find the sample app [here](https://github.com/aws-observability/aws-otel-community).

First, fork the repository. Then clone the repository and run the following commands:

```bash
$ cd ./sample-apps/prometheus
$ docker build . -t prometheus-sample-app:latest
```

In order to use this Docker image for Kubernetes, we need to push this image to a registry. You will need to push your image to your Amazon ECR or DockerHub registry. 

To deploy the sample app in EKS, copy this Kubernetes configuration and apply it. Make sure to use the latest image that was pushed.

```bash
$ curl https://raw.githubusercontent.com/aws-observability/aws-otel-collector/main/examples/eks/prometheus-pipeline/prometheus-sample-app.yaml -o prometheus-sample-app.yaml
```

Add your image reference to `prometheus-sample-app.yaml`

```bash
$ kubectl apply -f prometheus-sample-app.yaml
```

You can use the following command to verify that the sample app has started:

```bash
$ kubectl get all -n aoc-prometheus-pipeline-demo
NAME                                        READY   STATUS    RESTARTS   AGE
pod/prometheus-sample-app-6bfd56b57-8mzsb   1/1     Running   0          15m

NAME                                    TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
service/prometheus-sample-app-service   NodePort   10.100.246.31   <none>        8080:31653/TCP   15m

NAME                                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/prometheus-sample-app   1/1     1            1           15m

NAME                                              DESIRED   CURRENT   READY   AGE
replicaset.apps/prometheus-sample-app-6bfd56b57   1         1         1       15m
```

Any applications that you want to scrape should be instrumented with a [Prometheus client](https://prometheus.io/docs/instrumenting/clientlibs/) 
(this exposes Prometheus exposition metrics to a `/metrics` endpoint). This is done in the sample app as well.

<SubSectionSeparator />

### AWS Distro for OpenTelemetry (ADOT) Collector Setup


To start a default instance of the Collector, we have provided an example template configuration. This template will deploy the ADOT Collector as a DaemonSet.

In this example, the ADOT Collector configurations uses Prometheus’s Kubernetes service discovery in order to automatically find 
the sample app endpoint. An annotation (scrape=true) is used to determine which target endpoints to scrape. (This allows the ADOT Collector 
to distinguish between our sample app endpoint from kube-system endpoints within your cluster.) Feel free to remove this from the relabel 
configurations if you would like to scrape a different application.

To pull the Kubernetes configuration for ADOT Collector:

```bash
$ curl https://raw.githubusercontent.com/aws-observability/aws-otel-collector/main/examples/eks/prometheus-pipeline/eks-prometheus-daemonset.yaml -o eks-prometheus-daemonset.yaml
```

You will have to change the `<YOUR_ENDPOINT>` and `<YOUR_REGION>` to correspond with your own AMP workspace. The changes should be with respect to the AWS Prometheus Remote Write Exporter’s configuration. 

For Example:

```yaml lineNumbers=true 
exporters:
  awsprometheusremotewrite:
    endpoint: "https://aps-workspaces.us-west-2.amazonaws.com/workspaces/ws-d26e36bf-361j-480c-94f0-54bd7370f997/api/v1/remote_write"
    aws_auth:
      service: "aps"
      region: "us-west-2"
```


You’ll also need to change `<YOUR_ACCOUNT_ID>` (in the service account section of the Kubernetes configuration) to your AWS account ID. Now, to deploy the ADOT Collector in EKS, apply this Kubernetes config:

**Note: if you are using EKS on Fargate, you will need to change `DaemonSet` to `Deployment`. This is because DaemonSets are not supported by Fargate because there is no concept of nodes in Fargate.**

```bash
$ kubectl apply -f eks-prometheus-daemonset.yaml
```

You can verify that the ADOT Collector has started with this command:

```bash
$ kubectl get pods -n adot-col
NAMESPACE              NAME                                         READY   STATUS             RESTARTS   AGE
adot-col               adot-collector-7bc7c                         1/1     Running            0          3m17s
```

<SubSectionSeparator />

### Verifying the Pipeline Works

The logging exporter can be used to verify that metrics were scraped by the Prometheus Receiver. This example is already hooked up with the 
logging exporter. You can check the logs with these commands:

```bash
$ kubectl get pods -A
$ kubectl logs -n adot-col [name_of_your_adot_collector_pod]
```

An example of the scraped metrics in the logging exporter:

``` 
Resource labels:
     -> service.name: STRING(kubernetes-service-endpoints)
     -> host.name: STRING(192.168.16.238)
     -> port: STRING(8080)
     -> scheme: STRING(http)
InstrumentationLibraryMetrics #0
Metric #0
Descriptor:
     -> Name: test_gauge0
     -> Description: This is my gauge
     -> Unit: 
     -> DataType: DoubleGauge
DoubleDataPoints #0
StartTime: 0
Timestamp: 1606511460471000000
Value: 0.000000
```

In order to test if AMP received those metrics, we can use the awscurl. This tool allows us to send HTTPs requests through the command line with AWS 
Sigv4 authentication. In order to use this, make sure you have set the correct permissions to query from AMP in your local AWS credentials. Please use 
this guide to [install awscurl](https://github.com/okigan/awscurl).

You can use the following command below to check if a metric was received in AMP. The `AMP_REGION` and `AMP_ENDPOINT` will have to be changed 
corresponding to your AMP workspace.

```bash
$ awscurl --service="aps" --region="AMP_REGION" "https://{AMP_ENDPOINT}/api/v1/query?query=adot_test_gauge0"
{"status":"success","data":{"resultType":"vector","result":[{"metric":{"__name__":"adot_test_gauge0"},"value":[1606512592.493,"16.87214000011479"]}]}}
```

*Note*: *we added a `namespace: adot` value in the ADOT Collector yaml file to prefix each metric that is exported by ADOT Collector with `adot_`. *

<SubSectionSeparator />

### It Works!

If you receive a metric as the response, that means your pipeline setup is successful! This metric has successfully propagated from the sample app into AMP. 

Similar pipelines can be configured using the components mentioned above to scrape your Kubernetes cluster and applications. Please refer below for advanced configurations.

<SubSectionSeparator />

### Cleaning up 

Run the following commands to clean up your EKS cluster.

```bash
$ kubectl delete namespace aoc-prometheus-pipeline-demo
$ kubectl delete namespace adot-col
```

<SectionSeparator />

## Basic ECS Configuration for AMP

For ECS clusters powered by both AWS Fargate or AWS EC2, we will create a task definition of an ADOT Collector and a Prometheus metric emitter sample app. 

Our ADOT Collector configurations will contain two pipelines. 


* To scrape **application metrics**, we will configure the Prometheus Receiver to scrape application metrics from static hosts and export our metrics using the AWS Prometheus Remote Write Exporter.
* To scrape **ECS Metrics**, we will configure the AWS ECS Container Metrics Receiver to collect ECS metrics and another AWS Prometheus Remote Write Exporter to export metrics. 

<img src={prometheusPipelineECSImg} alt="Diagram" style="margin: 30px 0;" />

### Prerequisites

Before getting started, you will need to set up the following components:

* An AMP workspace should be set up. Guides for this can be found [here](https://docs.aws.amazon.com/prometheus/latest/userguide/what-is-Amazon-Managed-Service-Prometheus.html). 
* An ECS cluster with Fargate or EC2. If you need to set up an ECS cluster, please use the following [guide](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create_cluster.html). 

### Creating a IAM Policy

We need to create two IAM policies which will give the task role we create later the permissions to execute the actions necessary:

* **AWSDistroOpenTelemetryPolicy**: This policy will give permissions to create/describe logs and get your ADOT configurations from AWS Systems Manager Parameter Store (SSM Parameter Store).
* **AMPRemoteWritePolicy**: This policy will give permissions to remote write and query metrics from your AMP instance.

Please follow the steps outlined in this guide: [Creating an IAM policy](https://aws-otel.github.io/docs/setup/ecs/create-iam-policy). Note that you will need to use the policies we define below instead.

**AWSDistroOpenTelemetryPolicy:**

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "logs:PutLogEvents",
                "logs:CreateLogGroup",
                "logs:CreateLogStream",
                "logs:DescribeLogStreams",
                "logs:DescribeLogGroups",
                "ssm:GetParameters"
            ],
            "Resource": "*"
        }
    ]
}
```

**AMPRemoteWritePolicy:**

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "aps:RemoteWrite"
            ],
            "Resource": "*"
        }
    ]
}
```

### Creating an Task Role

After creating your IAM policies, we need to create a task role to execute the task. We will need to create a task role. 

Please follow this guide for [creating an IAM role](https://aws-otel.github.io/docs/setup/ecs/create-iam-role). However, when creating your Task Role (section 1.5), please remember to attach the **AMPRemoteWritePolicy** we just created above.

Now, we have defined the roles necessary to execute our ECS ADOT Collector configurations. Please follow the section below that fits your ECS cluster.

### Building our Sample App Image

We will be using a simple sample app that is used for the integration tests of this pipeline. You can find the sample app [here](https://github.com/aws-observability/aws-otel-community).

First, fork the repository. Then clone the repository and run the following commands:

```bash
$ cd ./sample-apps/prometheus
$ docker build . -t prometheus-sample-app:latest
```

Next, push this image to a remote repository on either ECR or Dockerhub so that it can be used by the ECS deployment

### Demonstration 1: ECS Powered by Fargate

1. [Download the ECS Fargate AMP task definition template from Github.](https://github.com/aws-observability/aws-otel-collector/tree/main/examples/ecs/prometheus-pipeline/ecs-fargate-task-def.json) This definition specifies a Prometheus sample app and an ADOT Collector instance. If you would like to learn more about the sample app, please visit [here](https://github.com/aws-observability/aws-otel-community/tree/master/sample-apps/prometheus).
2. Fill the following parameters in the task definition templates:
    * `region` - the region the data will be sent to
    * `ecsTaskRoleArn` - AWSOTTaskRole ARN created in the previous section
    * `ecsExecutionRoleArn` - AWSOTTaskExcutionRole ARN created in the previous section
    * `sampleAppImage` - the image to the Prometheus sample app we created above
3. Follow the [ECS task definition setup instructions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-task-definition.html), and use the “Fargate Launch Type” instructions step 1 to create a task definition using the given template.
    * Be sure to verify all of the fields match the template
4. [Download the custom ADOT Collector configuration.](https://github.com/aws-observability/aws-otel-collector/tree/main/examples/ecs/prometheus-pipeline/ecs-fargate-adot-config.yaml) This configuration uses the Prometheus Receiver to scrape from a static target. Notice that our sample app is automatically deployed on port 8080. 
    * Fill the following parameters in the ADOT Collector configuration:
      * `region` - the region the data will be sent to
      * `endpoint` - the AMP remote_write endpoint which we will export data to
5. To use our custom ADOT Collector configuration, we can [set up a custom configuration file using SSM Parameter](https://aws-otel.github.io/docs/setup/ecs/config-through-ssm). 
6. Now, [deploy your task on ECS](https://aws-otel.github.io/docs/setup/ecs/run-task). 

### Demonstration 2: ECS Powered by AWS EC2

Note that you must have a cluster created with an EC2 instance available. We chose “EC2 Linux + Networking” template. For more detailed cluster setup please refer to the link in the prerequisites section of this document.

<img src={createClusterECSImg} alt="Diagram" style="margin: 30px 0;" />

1. [Download the ECS EC2 AMP task definition template from Github](https://github.com/aws-observability/aws-otel-collector/tree/main/examples/ecs/prometheus-pipeline/ecs-ec2-task-def.json). This definition specifies a Prometheus sample app and an ADOT Collector instance. If you would like to learn more about the sample app, please visit [here](https://github.com/aws-observability/aws-otel-community/tree/master/sample-apps/prometheus).
2. Fill the following parameters in the task definition templates:
    * `region` - the region the data will be sent to
    * `ecsTaskRoleArn` - AWSOTTaskRole ARN created in the previous section
    * `ecsExecutionRoleArn` - AWSOTTaskExcutionRole ARN created in the previous section
    * `sampleAppImage` - the image to the Prometheus sample app we created above
3. Follow the [ECS task definition setup instructions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create-task-definition.html), and use the “EC2 Launch Type” instructions step 1 to create a task definition using the given template.
    * Be sure to verify all of the fields match the template
4. [Download the custom ADOT Collector configuration](https://github.com/aws-observability/aws-otel-collector/tree/main/examples/ecs/prometheus-pipeline/ecs-ec2-adot-config.yaml). This configuration uses the Prometheus Receiver to scrape from a static target using an environment variable.
    * Fill the following parameters in the ADOT Collector configuration:
        * `region` - the region the data will be sent to
        * `endpoint` - the AMP remote_write endpoint which we will export data to
5. To use our custom ADOT Collector configuration, we can [set up a custom configuration file using SSM Parameter](https://aws-otel.github.io/docs/setup/ecs/config-through-ssm). 
6. Now, [deploy your task on ECS](https://aws-otel.github.io/docs/setup/ecs/run-task). 

### Results

#### Query for AMP metrics

In order to test if AMP received those metrics, we can use the awscurl. This tool allows us to send HTTPs requests through the command line with AWS Sigv4 authentication. In order to use this, make sure you have set the correct permissions to query from AMP in your local AWS credentials. Please use this guide to install [awscurl](https://github.com/okigan/awscurl).

You can use the following command below to check if a metric was received in AMP. The region and AMP_ENDPOINT will have to be changed corresponding to your AMP workspace.

```bash
$ awscurl --service="aps" --region="region" "https://{AMP_ENDPOINT}/api/v1/query?query=adot_test_gauge0"
{"status":"success","data":{"resultType":"vector","result":[{"metric":{"__name__":"adot_test_gauge0"},"value":[1606512592.493,"16.87214000011479"]}]}}
```

Note: we added a namespace: adot value in the ADOT Collector yaml file to prefix each metric that is exported by ADOT Collector with adot_. 

#### Visualize metrics in AWS Managed Service for Grafana 

If you are using AWS Managed Service for Grafana (AMG), we can visualize and list the metrics we found. For example, the AWS ECS Container Metrics Receiver will produce the following metrics:

<img src={availableMetricsECSImg} alt="Diagram" style="margin: 30px 0;" />

<SectionSeparator />

## Components in our Pipeline

#### Prometheus Receiver

The Prometheus Receiver supports the full set of Prometheus scraping and re-labeling configurations described 
[here](http://prometheus.io/docs/prometheus/latest/configuration/configuration/). You should be able to directly paste in these configurations into your 
ADOT Collector configurations. 

The configuration for the Prometheus Receiver will include your service discovery, scraping configurations, and re-labeling configurations. The 
receiver configurations will look like this:

```yaml lineNumbers=true
receivers:
  prometheus:
    config:
      [Your Prometheus configurations]
```

An example configuration is shown below. 

```yaml lineNumbers=true 
receivers:
  prometheus:
    config:
      global:
        scrape_interval: 1m
        scrape_timeout: 10s
        
      scrape_configs:
      - job_name: kubernetes-service-endpoints
        sample_limit: 10000
        kubernetes_sd_configs:
        - role: endpoints
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
```

**Note:** To perform Kubernetes service discovery, you will need to set up the proper permissions and RBAC authorization for the service account 
(to allow it to access the Kubernetes API). Please refer to the Permissions section in the 
[advanced configurations doc](/docs/getting-started/advanced-prometheus-remote-write-configurations).

**Note: If you have existing Prometheus configurations, you will need to replace the `$` characters with `$$` to avoid having the value replaced with environment variables. **
This is especially important for the `replacement` value of the relabel_configurations. For instance, the following configuration for relabel_configurations below 

```
relabel_configs:
- source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
  regex: (.+);(.+);(.+)
  replacement: ${1}://${2}${3}
  target_label: __param_target
```

would become 

```
relabel_configs:
- source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
  regex: (.+);(.+);(.+)
  replacement: $${1}://${2}${3}
  target_label: __param_target
```

#### AWS Prometheus Remote Write Exporter

The configuration for the AWS Prometheus Remote Write Exporter is a lot simpler than the Prometheus receiver. At this stage in the pipeline, metrics 
have already been ingested, and we’re ready to export this data to AMP. The minimum requirement for a successful configuration to communicate with AMP is as follows:

```yaml lineNumbers=true 
exporters:
  awsprometheusremotewrite:
    endpoint: "https://aws-managed-prometheus-endpoint/v1/api/remote_write"
    aws_auth:
      service: "aps"
      region: "user-region"
```

This configuration sends an HTTPS request that is signed by AWS SigV4 using the credentials that are set up from the prerequisites section. It is 
mandatory that customers specify the service to be “aps”

Regardless of the method of deployment, the ADOT Collector must have access to one of the listed options in the 
[default AWS credentials chain](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html). The AWS Prometheus Remote Write 
Exporter depends on the AWS Go SDK and uses it to fetch credentials and authenticate. You must ensure that these credentials have remote writing 
permissions to AMP (`aps:RemoteWrite`).

<SectionSeparator />

## Conclusion 

This document has gone over what the basic requirements are to get set up with the ADOT Collector to collect and export Prometheus metrics to AMP. 
With this, you should be able to use the aforementioned tools to have a clean solution to observability on your software systems. 

For more advanced configurations with the ADOT Collector-AMP, please take a look [here](/docs/getting-started/advanced-prometheus-remote-write-configurations).

We would love to hear more common configuration scenarios or improvements to this documentation from you! Please submit an issue 
on the [aws-otel community](https://github.com/aws-observability/aws-otel-community) to let us know.

