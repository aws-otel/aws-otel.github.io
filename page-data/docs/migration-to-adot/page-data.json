{
    "componentChunkName": "component---node-modules-rocketseat-gatsby-theme-docs-core-src-templates-docs-query-js",
    "path": "/docs/migration-to-adot",
    "result": {"data":{"mdx":{"id":"71e452d0-25de-5502-82d2-ed4446b7c1c5","excerpt":"In this blog we assume that you’re somewhat familiar with Prometheus and are in the process to migrate to an OpenTelemetry-based setup for collecting your…","fields":{"slug":"/docs/migration-to-adot/"},"frontmatter":{"title":"Migrating from Prometheus to AWS Distro for OpenTelemetry (ADOT)","description":"In this blog we assume that you’re somewhat familiar with Prometheus and are in the process to migrate to an OpenTelemetry-based setup for collecting your metrics. We show the migration steps, discuss how to address compatibility challenges and provide guidance on the usage of the OpenTelemetry setup to collect Prometheus metrics.","image":null,"disableTableOfContents":null},"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Migrating from Prometheus to AWS Distro for OpenTelemetry (ADOT)\",\n  \"description\": \"In this blog we assume that you’re somewhat familiar with Prometheus and are in the process to migrate to an OpenTelemetry-based setup for collecting your metrics. We show the migration steps, discuss how to address compatibility challenges and provide guidance on the usage of the OpenTelemetry setup to collect Prometheus metrics.\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"In this blog we assume that you\\u2019re somewhat familiar with Prometheus and are in the process to migrate to an OpenTelemetry-based setup for collecting your metrics.\\nWe show the migration steps, discuss how to address compatibility challenges and provide guidance on the usage of the OpenTelemetry setup to collect Prometheus metrics.\"), mdx(\"h2\", {\n    \"id\": \"introduction\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#introduction\",\n    \"aria-label\": \"introduction permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Introduction\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://prometheus.io/\"\n  }, \"Prometheus\"), \" is an open-source systems monitoring and alerting toolkit which simplifies the monitoring and observability of distributed systems,\\nallowing developers and operators to gain insights into their applications' health and performance. It is a widely used tool for collecting and visualizing metrics, known for its operational simplicity.\"), mdx(\"p\", null, \"The \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/aws-observability/aws-otel-collector\"\n  }, \"AWS Distro for OpenTelemetry (ADOT) collector\"), \" is an AWS-supported distribution of the OpenTelemetry Collector,\\na vendor-agnostic component of the OpenTelemetry project. ADOT is a secure, production-ready open-source distribution for use with AWS computing platforms, including Amazon Elastic Kubernetes Service\\n(EKS , Amazon Elastic Container Service (ECS), AWS Lambda and Amazon EC2 . The ADOT collector allows you to collect both traces and metrics with a single agent and ingest them into\\nAWS observability services such as Amazon CloudWatch, AWS X-Ray, Amazon Managed Service for Prometheus (AMP), and Amazon OpenSearch (AOS). To change the telemetry signal destination is as easy as\\nchanging the configuration of the ADOT collector.\"), mdx(\"p\", null, \"OpenTelemetry represents a super-set of Prometheus, from a signal perspective by supporting distributed traces, metrics and logs. \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://opentelemetry.io/docs/concepts/signals/traces/\"\n  }, \"Traces\"), \"\\nhelp us understand how different parts of the system work together and find any issues that might slow things down. By identifying these problem areas, we can make improvements that enhance the\\noverall performance of the system, \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://opentelemetry.io/docs/demo/scenarios/recommendation-cache/\"\n  }, \"see this example to diagnose the memory leak\"), \" using traces and metrics.\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/prometheus\"\n  }, \"Prometheus\"), \" excels in time series-based monitoring and alerting. OpenTelemetry provides exceptional integration flexibility. It offers exporters and integrations\\nwith diverse monitoring and observability systems, effortlessly integrating with\\nexisting tools and infrastructure. This empowers organizations to leverage their current monitoring ecosystems, ensuring a smooth transition while minimizing operational complexity.\"), mdx(\"h2\", {\n    \"id\": \"steps-to-migrate\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#steps-to-migrate\",\n    \"aria-label\": \"steps to migrate permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Steps To Migrate\"), mdx(\"p\", null, \"The migration steps from Prometheus as the collection mechanism to the ADOT collector are as follows.\"), mdx(\"h3\", {\n    \"id\": \"prometheus-setup\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#prometheus-setup\",\n    \"aria-label\": \"prometheus setup permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Prometheus setup\"), mdx(\"p\", null, \"Assess your existing Prometheus configuration, including Prometheus server configuration, scrape configurations, alerting rules, and recording rules. Identify metrics, labels, and\\nconfigurations that need to be migrated. Let's examine a concrete end-to-end example of a Prometheus server and how it can be configured to remote-write metrics to AMP.\"), mdx(\"p\", null, \"This diagram shows an end-to-end pipeline for scraping the Prometheus metrics using the Prometheus server and remote writing to the monitoring destination Amazon Managed Service for Prometheus, visualizing in Amazon Managed Grafana (AMG).\"), mdx(\"img\", {\n    src: prometheuspipeline,\n    alt: \"Prometheus based metrics pipeline\",\n    style: {\n      \"margin\": \"20px 0\"\n    }\n  }), mdx(\"p\", null, \"First, capture the config by saving the following Prometheus configuration as a file named \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"prometheus.yml\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-console\"\n  }, \"global:\\n  scrape_interval: 15s\\n\\n# Remote writing the exporter\\nremote_write:\\n  - url: <YOUR_REMOTE_WRITE_ENDPOINT>\\n    sigv4:\\n      region: <YOUR_AWS_REGION>\\n\\nscrape_configs:\\n\\n# Scraping job using 'static_config'\\n    job_name: \\\"Scrape-job\\\"\\n      static-config:\\n      - targets: [localhost:9001]\\n\\n# Prometheus self Telemetry\\n  - job_name: 'self-telemetry-prometheus'\\n    scrape_interval: 5s\\n    static_configs:\\n      - targets: [\\\"localhost:9090\\\"]\\n\")), mdx(\"p\", null, \"Make sure to replace <YOUR_REMOTE_WRITE_ENDPOINT> and <YOUR_AWS_REGION> in the remotewrite .\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-console\"\n  }, \"# Download the prometheus for your platform, modify the url as needed.\\nwget https://github.com/prometheus/prometheus/releases/download/v2.43.0%2Bstringlabels/prometheus-2.43.0+stringlabels.linux-amd64.tar.gz\\n\\n# Extract the file\\ntar xvfz prometheus-*.tar.gz\\n\")), mdx(\"p\", null, \"Navigate to the folder and run the prometheus.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-console\"\n  }, \"// Navigate inside the extracted prometheus folder\\ncd prometheus-*\\n\\n// Run Prometheus\\n./prometheus --config.file=prometheus.yml\\n\")), mdx(\"p\", null, \"You can run Prometheus in agent mode, which is a specialized mode in Prometheus that optimizes it for the remote-write use case. It disables querying, alerting, and local storage,\\nutilizing a customized Time Series Data Base Write Ahead Logs (TSDB WAL) instead. The scraping logic, service discovery, and related configurations remain unchanged:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-console\"\n  }, \"// Command to run Prometheus in Agent Mode\\n./prometheus --config.file=prometheus.yml --enable-feature=agent\\n\")), mdx(\"p\", null, \"To confirm that the Prometheus server is operational, you can check if it has started up successfully. Verify that Prometheus is serving metrics related to its own performance by accessing\\nits metrics endpoint -\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"localhost:9090/metrics\"), \". Allow a few seconds for Prometheus to collect self-data from its HTTP metrics endpoint and the data is exported to AMP.\"), mdx(\"p\", null, \"You can also run the following \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-compatible-APIs.html\"\n  }, \"awscurl command\"), \" to check if Amazon Managed Prometheus received the Prometheus metrics data, replace the <YOUR_AWS_REGION> and <YOUR_AMP_WORKSPACE_ID> fields for both queries.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-console\"\n  }, \"$ awscurl --service=\\\"aps\\\" --region=\\\"<YOUR_AWS_REGION>\\\" \\\\\\n\\\"https://aps-workspaces..amazonaws.com/workspaces//api/v1/query?query=scrape_duration_seconds\\\"\\n\")), mdx(\"p\", null, \"Your output should look something like this:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"{\\\"status\\\":\\\"success\\\",\\\"data\\\":{\\\"resultType\\\":\\\"vector\\\",\\\"result\\\":[{\\\"metric\\\":{\\\"EKS_Container\\\":\\\"cert-manager\\\",\\\"EKS_Namespace\\\":\\\"cert-manager\\\",\\\"EKS_PodName\\\":\\\"cert-manager-858bf78c95-qvq2j\\\",\\\"__name__\\\":\\\"scrape_duration_seconds\\\",\\\"app\\\":\\\"cert-manager\\\",\\\"app_kubernetes_io_component\\\":\\\"controller\\\",\\\"app_kubernetes_io_instance\\\":\\\"cert-manager\\\",\\\"app_kubernetes_io_name\\\":\\\"cert-manager\\\",\\\"instance\\\":\\\"192.168.41.17:9402\\\",\\\"job\\\":\\\"storefront\\\",\\\"pod_template_hash\\\":\\\"858bf78c95\\\"},\\\"value\\\":[1636159948.136,\\\"0.001410662\\\"]}]}}\\n\")), mdx(\"h3\", {\n    \"id\": \"adot-collector-setup\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#adot-collector-setup\",\n    \"aria-label\": \"adot collector setup permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"ADOT Collector setup\"), mdx(\"p\", null, \"Now, let's understand the OpenTelemetry pipeline and the configuration for using the ADOT collector. This diagram shows an end-to-end pipeline for scraping the Prometheus metrics using the ADOT collector and remote-writing to the monitoring destination AMP, visualizing in AMG.\"), mdx(\"img\", {\n    src: adotcollector,\n    alt: \"OpenTelemetry based metrics pipeline\",\n    style: {\n      \"margin\": \"20px 0\"\n    }\n  }), mdx(\"p\", null, \"The following collector configuration, consisting of receivers, processors, and exporters, enables remote achieves the same result as the earlier example of Prometheus server configuration:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-console\"\n  }, \"extensions:\\n  sigv4auth:\\n    region: \\\"<YOUR-REGION>\\\"\\n\\nreceivers:\\n  prometheus:\\n    config:\\n      global:\\n        scrape_interval: 15s\\n      scrape_configs:\\n      # Scraping job using 'static_config'\\n      - job_name: \\\"Scrape-job\\\"\\n        static-config:\\n        - targets: [localhost:9001]\\n\\nprocessors:\\n  batch:\\n\\nexporters:\\n  prometheusremotewrite:\\n    endpoint: \\\"<remote-write-endpoint>\\\"\\n    auth:\\n      authenticator: sigv4auth\\n\\nservice:\\n  pipelines:\\n    metrics:\\n     receivers: [prometheus]\\n     processors: [batch]\\n     exporters: [prometheusremotewrite]\\n  extensions: [sigv4auth]\\n\")), mdx(\"p\", null, \"In the ADOT collector, the combination of receivers, processors, extensions, and exporters form a pipeline that handles various tasks to achieve remote writing to AMP. Here's how each component contributes to the overall process:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/README.md\"\n  }, \"Receivers\"), \": Receivers play the role of collecting telemetry data from from different sources. It serves as the entry point for data and\\naccepts data in a specified format, translates it into the internal format and passes it to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/README.md\"\n  }, \"processors\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/README.md\"\n  }, \"exporters\"), \"\\ndefined in the pipeline. \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/prometheusreceiver#readme\"\n  }, \"Prometheus Receiver\"), \" collects metrics from various targets and is responsible for scraping\\nmetrics from prometheus endpoints, it receives metric data in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://prometheus.io/\"\n  }, \"Prometheus\"), \" format. It can be configured using your existing \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://prometheus.io/docs/prometheus/latest/configuration/configuration/\"\n  }, \"Prometheus configurations\"), \" to perform service discovery and metric scraping.\\nThe primary purpose of the Prometheus receiver is to serve as a direct replacement for Prometheus with minimal effort. However, it is important to note that the receiver \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/prometheusreceiver#unsupported-features\"\n  }, \"does not support certain advanced features\"), \" of Prometheus.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/README.md\"\n  }, \"Processors\"), \": Processors are optional components and not processors enabled by default. Typically, a processor performs data pre-processing prior to exportation or aids in ensuring that data makes it through a pipeline successfully.\\nTo optimize performance, it is strongly recommended to include the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/batchprocessor#readme\"\n  }, \"batch processor\"), \" configuration in each collector. The batch processor should be placed in the pipeline after the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/memorylimiterprocessor#readme\"\n  }, \"memory_limiter\"), \" and any sampling processors that are present.\\nThis ensures efficient processing and handling of telemetry data in a controlled manner\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/blob/main/extension/README.md\"\n  }, \"Extensions\"), \": Extensions enhance the core functionality of the collector by providing additional capabilities. In general, extensions are utilized\\nto implement components that can be seamlessly incorporated into the Collector. The \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://Sigv4%20authentication\"\n  }, \"Sigv4AuthExtension\"), \" here enables \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html\"\n  }, \"Sigv4 authentication\"), \"\\na protocol for authenticating inbound API requests to AWS services, for making requests to AWS services. Some examples of extensions include the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/healthcheckextension#readme\"\n  }, \"Health Check extension\"), \",\\nwhich responds to health check requests, and the PProf extension, which enables the retrieval of the Collector's performance profile.\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/README.md\"\n  }, \"Exporters\"), \": Exporters are responsible for sending the processed and transformed data to external systems, such as Prometheus Remote Write\\nexporter in this case, it sends metrics to a remote write destination compatible with the\\nPrometheus remote write API by using the remote_write endpoint. The HTTPS requests used to export data will be signed with AWS SigV4, using the sigv4auth extension.\"))), mdx(\"p\", null, \"The ADOT collector is constructed with a preconfigured setup that adheres to a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/aws-observability/aws-otel-collector/blob/main/config.yaml\"\n  }, \"default configuration\"), \". The configuration of the ADOT collector\\nfollows the same syntax and design as the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector\"\n  }, \"OpenTelemetry Collector\"), \".\"), mdx(\"h3\", {\n    \"id\": \"design-migration-strategy\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#design-migration-strategy\",\n    \"aria-label\": \"design migration strategy permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Design migration strategy\"), mdx(\"p\", null, \"Plan your migration strategy based on your specific requirements. Consider factors such as the scope of the migration, the metrics you want to migrate, any customizations or transformations needed, and the timeline\\nfor the migration. It is important that you are aware of the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"following compatibility challenges\"), \" when you plan your migration.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Metric Relabeling\"), \" - When writing \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"relabel_configs\"), \" in the collector config \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"prometheusreceiver\"), \" one can not use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"$\"), \" but has to use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"$$\"), \". If you have existing Prometheus configurations, you will need to replace the $ characters with $$\\nto avoid having the value replaced with environment variables. This is especially important for the replacement value of the relabel_configurations. For instance, the following configuration for relabel_configs below\"), mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"```\\nrelabel_configs:\\n- source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]\\n  regex: (.+);(.+);(.+)\\n  replacement: ${1}://${2}${3}\\n  target_label: __param_target\\n```\\n\")), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"  would become\"), mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"```\\nrelabel_configs:\\n- source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]\\n  regex: (.+);(.+);(.+)\\n  replacement: $${1}://$${2}$${3}\\n  target_label: __param_target\\n```\\n\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Retrying in 5xx error\"), \" - The Prometheus Remote Write exporter has a limitation in the ADOT collector as it does not retry on 5xx error codes. It is currently treating it in the same way as 4xx codes and hence leading to failures in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/prometheus/compliance\"\n  }, \"compliance test\"), \"\\nof Prometheus conformance program. \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/20304\"\n  }, \"This issue\"), \" can have implications for data reliability and consistency when using the Prometheus remote write functionality.\\nIt may result in data loss or gaps in the exported metrics if the exporter does not handle server errors appropriately. Enable \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/troubleshooting.md#logs\"\n  }, \"debug logging\"), \" and\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/tree/main/exporter/loggingexporter\"\n  }, \"logging exporter\"), \" with \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"verbosity:detailed\"), \" in your collector configuration, analyze the logs to understand if the exporter is failed to retry on 5xx errors.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Batch Size of Prometheus Remote Write Exporter\"), \" - The Prometheus Remote Write exporter has a batch size limit that restricts the number of samples in each batch sent to a remote write endpoint. The limit can vary based on prometheus time series data and configuration as well. If the sample count exceeds the limit,\\ndata is split into multiple batches. Optimize data transmission efficiency and performance by considering the batch size limit.\"))), mdx(\"h3\", {\n    \"id\": \"monitor-and-optimize\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#monitor-and-optimize\",\n    \"aria-label\": \"monitor and optimize permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Monitor and optimize\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"TIP\"), \": We have a dedicated section on \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws-observability.github.io/observability-best-practices/guides/operational/adot-at-scale/operating-adot-collector/\"\n  }, \"operating the ADOT collector at scale\"), \" in the AWS Observability Best Practices site.\")), mdx(\"p\", null, \"The ADOT collector generates its own telemetry that providing insights into its performance to leverage its built-in capabilities that helps to optimize your metrics collection, Monitor metrics such as\\nCPU and memory usage, ingestion rate, and queue size to ensure the Collector is operating efficiently.\"), mdx(\"p\", null, \"Configure the telemetry under the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://opentelemetry.io/docs/collector/configuration/#service\"\n  }, \"service\"), \" as shown below in your configuration to gain valuable insights and take prompt action.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"service:\\n  telemetry:\\n    logs:\\n      level: debug\\n    metrics:\\n      level: detailed\\n      address: 0.0.0.0:8888\\n\")), mdx(\"p\", null, \"One should enable self telemetry in their collector and consider ways to \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"scale\")), \" the pipeline as your telemetry collection increases. When it comes to the Prometheus receiver, for example,\\nif the duration it takes to complete scraping all targets (measured by \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"scrape_duration_seconds\"), \") approaches the scrape_interval you defined in the configuration, It is crucial to consider scaling or\\nsharding the scraping process. This involves adding more scrapers, typically in the form of new Collector instances.\"), mdx(\"p\", null, \"Also, metrics associated with exporter queue sizes can be highly informative. Specifically, the metrics \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"otelcol_exporter_queue_capacity\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"otelcol_exporter_queue_size\"), \" can provide valuable indicators.\\nWorkers are concurrent goroutines that execute tasks concurrently to achieve parallelism and efficient utilization of system resources, collector temporarily holds data in memory until a\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/403b0eff117df29d969cc18706d1c58b605db8e2/cmd/telemetrygen/internal/metrics/worker.go#L19-L27\"\n  }, \"worker\"), \" becomes available to transmit the data.\\nInsufficient worker availability or slow backend systems can result in a backlog of data accumulating in the queue. When the queue reaches its capacity (\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"otelcol_exporter_queue_size\"), \" > \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"otelcol_exporter_queue_capacity\"), \"),\\ndata gets rejected (\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"otelcol_exporter_enqueue_failed_metric_points\"), \"). See also \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://opentelemetry.io/docs/collector/scaling/#when-to-scale\"\n  }, \"Scaling the Collector\"), \".\"), mdx(\"p\", null, \"Consistently monitor and enhance your OpenTelemetry deployment by making necessary adjustments and fine-tuning the configuration. Lets say you are seeing a high resource (CPU/Memory) utilization of the collector when scraping\\n70k samples when using the basic configuration referred earlier in the guide, you can configure \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/batchprocessor#readme\"\n  }, \"batch processor\"), \" to enhance\\ndata compression and minimize the quantity of outgoing connections\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"extensions:\\n  sigv4auth:\\n    region: \\\"us-west-2\\\"\\n\\nreceivers:\\n  prometheus:\\n    config:\\n      global:\\n        scrape_interval: 15s\\n      scrape_configs:\\n      - job_name: \\\"Scrape-job\\\"\\n        static-config:\\n        - targets: [localhost:9001]\\n\\n#configured batch processor\\nprocessors:\\n  batch:\\n    send_batch_max_size: 70000\\n    timeout: 1s\\n\\nexporters:\\n  prometheusremotewrite:\\n    endpoint: \\\"<remote-write-endpoint>\\\"\\n    auth:\\n      authenticator: sigv4auth\\n\\nservice:\\n  pipelines:\\n    metrics:\\n     receivers: [prometheus]\\n     processors: [batch]\\n     exporters: [prometheusremotewrite]\\n  extensions: [sigv4auth]\\n\")), mdx(\"p\", null, \"The following graph illustrates the memory and cpu usage of ADOT collector with default configuration (green) and configured batch processor (yellow) at 70,000,  memory consumption of the collector with custom configuration is low and stable,\\nwhile the collector may consume a bit more CPU than before:\"), mdx(\"img\", {\n    src: batchimage,\n    alt: \"Diagram\",\n    style: {\n      \"margin\": \"20px 0\"\n    }\n  }), mdx(\"p\", null, \"Comparing the ADOT collector and Prometheus in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://prometheus.io/blog/2021/11/16/agent/\"\n  }, \"agent mode\"), \", the ADOT collector exhibits better memory performance for workloads up to 70k samples per instance. This advantage holds true across various scenarios,\\nincluding load testing, varying metric-count/series count ratio, and scraping from multiple endpoints with default configurations. Notably, the queue size of the ADOT Collector increases over time. However, it's important to acknowledge that the ADOT collector\\nconsumes more CPU than Prometheus in all scenarios, even when Prometheus operates in agent mode.\"), mdx(\"h2\", {\n    \"id\": \"demo\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#demo\",\n    \"aria-label\": \"demo permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Demo\"), mdx(\"p\", null, \"This demonstration showcases the utilization of the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws-otel.github.io/docs/getting-started/adot-eks-add-on\"\n  }, \"ADOT EKS add-on\"), \" to deploy the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/open-telemetry/opentelemetry-operator\"\n  }, \"OpenTelemetry Operator\"), \" onto an Amazon EKS cluster.\\nThroughout this process, the metrics gathered from a Prometheus sample application are collected and exported to the AMP monitoring destination. Subsequently, these metrics are visualized in Grafana. The add-on watches for a custom resource named \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"OpenTelemetryCollector\"), \"\\nand manages the lifecycle of an ADOT collector based on the configuration settings specified in the custom resource. The following figure shows an illustration of how this works:\"), mdx(\"img\", {\n    src: addonexample,\n    alt: \"ADOT EKS add-on setup\",\n    style: {\n      \"margin\": \"20px 0\"\n    }\n  }), mdx(\"h3\", {\n    \"id\": \"prerequisites\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#prerequisites\",\n    \"aria-label\": \"prerequisites permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Prerequisites\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The AWS CLI v2 is installed and configured in your environment.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You need to install the eksctl command in your environment\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You need to install kubectl in your environment.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You have docker installed into your environment.\")), mdx(\"h3\", {\n    \"id\": \"setup\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#setup\",\n    \"aria-label\": \"setup permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Setup\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"You can either use an existing EKS cluster or create one using \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://aws-observability.github.io/observability-best-practices/recipes/recipes/ec2-eks-metrics-go-adot-ampamg/cluster-config.yaml\"\n  }, \"cluster-config.yaml\"), \".\\nEdit the template file and set <YOUR_REGION>  and the version to \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"1.26\"), \" or any of \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html\"\n  }, \"Amazon EKS Kubernetes versions\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Install cert-manager with the command:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.12.1/cert-manager.yaml\\n\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Check that cert-manager is ready with the following command:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"kubectl get pod -w -n cert-manager\\n\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Create Amazon Managed Prometheus console using the console: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://console.aws.amazon.com/prometheus/home\"\n  }, \"https://console.aws.amazon.com/prometheus/home\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Create AMG workspace using the Amazon Managed Grafana \\u2013 Getting Started guide.\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Add \\\"Amazon Managed Service for Prometheus\\\" as a datasource during creation.\")))), mdx(\"h3\", {\n    \"id\": \"deploy-sample-application\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#deploy-sample-application\",\n    \"aria-label\": \"deploy sample application permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Deploy sample application\"), mdx(\"p\", null, \"In this demo we will be using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/aws-observability/aws-otel-community/tree/master/sample-apps/prometheus-sample-app\"\n  }, \"prometheus-sample-app\"), \" from the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/aws-observability/aws-otel-community\"\n  }, \"aws-otel-community\"), \" repository. This Prometheus sample app generates all four Prometheus metric types (counter, gauge, histogram, summary) and exposes them at the /metrics endpoint.\"), mdx(\"p\", null, \"To build the container image, first clone the Git repository and change into the directory as follows:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"git clone https://github.com/aws-observability/aws-otel-community.git && \\\\\\ncd aws-otel-community/sample-apps/prometheus-sample-app/ && \\\\\\ndocker build . -t \\\"prometheus-sample-app\\\"\\n\")), mdx(\"p\", null, \"Now that the image is built, tag and push the docker image to your ECR repo by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.aws.amazon.com/AmazonECR/latest/public/docker-push-ecr-image.html\"\n  }, \"following this documentation\"), \".\"), mdx(\"p\", null, \"Edit \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws-observability.github.io/observability-best-practices/recipes/recipes/ec2-eks-metrics-go-adot-ampamg/prometheus-sample-app.yaml\"\n  }, \"prometheus-sample-app.yaml\"), \" to contain your ECR image path and any other configurations in the file with your own values:\"), mdx(\"p\", null, \"Now you can deploy the sample app to your cluster using the following command:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"kubectl apply -f prometheus-sample-app.yaml\\n\")), mdx(\"p\", null, \"You can associate your IAM role to your EKS service account using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/setting-up-enable-IAM.html\"\n  }, \"IRSA\"), \". Your service account can then provide AWS permissions to the containers you run in any pod that use that service account. You must use this command for each cluster where you're installing ADOT to grant your AWS service account permissions. Follow these steps to associate your IAM role to your EKS service account using IRSA.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-console\"\n  }, \"eksctl create iamserviceaccount \\\\\\n    --name adot-collector \\\\\\n    --namespace aws-otel-eks \\\\\\n    --cluster <your_cluster_name> \\\\\\n    --attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess \\\\\\n    --attach-policy-arn arn:aws:iam::aws:policy/AWSXrayWriteOnlyAccess \\\\\\n    --attach-policy-arn arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy \\\\\\n    --approve \\\\\\n    --override-existing-serviceaccounts\\n\")), mdx(\"p\", null, \"We will see in our collector configurations in later sections that we add the serviceAccount: adot-collector field to our configuration to use IRSA.\"), mdx(\"p\", null, \"EKS add-on now provides the ability to configure ADOT during installation time. With this functionality, an ADOT Collector can also be deployed during an installation like below.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Create \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"configuration-values.json\"), \" with the following contents. Replace \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"<YOUR_REMOTE_WRITE_ENDPOINT>\"), \"  with your own:\"), mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"{\\n       \\\"collector\\\": {\\n         \\\"serviceAccount\\\": {\\n           \\\"create\\\": false,\\n           \\\"name\\\": \\\"adot-collector\\\"\\n         },\\n         \\\"amp\\\": {\\n           \\\"enabled\\\": true,\\n           \\\"remoteWriteEndpoint\\\": \\\"<YOUR_REMOTE_WRITE_ENDPOINT>\\\"\\n         }\\n       }\\n     }\\n\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Run the following command. Replace <your_cluster_name> with your own.\"), mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"aws eks create-addon \\\\\\n        --cluster-name <your_cluster_name> \\\\\\n        --addon-name adot \\\\\\n        --addon-version v0.76.1-eksbuild.1 \\\\\\n        --configuration-values file://configuration-values.json\\n\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Verify that ADOT add-on is installed and running with the command:\"), mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"aws eks describe-addon --addon-name adot --cluster-name <your_cluster_name>\\n\")))), mdx(\"p\", null, \"You'll see \\\"status\\\": \\\"ACTIVE\\\" when creation is complete. Note that collector may take up to 2 minutes to create and show up in your cluster.\"), mdx(\"p\", null, \"Alternatively, If you wish to have complete control you can Install the ADOT Operator into your Amazon EKS cluster using the following command and deploy collector:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"aws eks create-addon --addon-name adot --cluster-name <your_cluster_name>\\n\")), mdx(\"p\", null, \"The collector configuration deployment template below allows you to manage everything on your own which also creates  ClusterRole and ClusterRoleBinding to provide necessary permissions for the prometheus receiver during service discovery. Save this into a file called collector-config-amp.yaml .\"), mdx(\"details\", null, mdx(\"summary\", null, \"Click here to expand the collector configuration\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"#\\n# OpenTelemetry Collector configuration\\n# Metrics pipeline with Prometheus Receiver and Prometheus Remote Write Exporter sending metrics to Amazon Managed Prometheus\\n#\\n# create namespace\\napiVersion: v1\\nkind: Namespace\\nmetadata:\\n  name: aws-otel-eks\\n  labels:\\n    name: aws-otel-eks\\n\\n---\\n# create cwagent service account and role binding\\napiVersion: v1\\nkind: ServiceAccount\\nmetadata:\\n  name: adot-collector\\n  namespace: aws-otel-eks\\n\\n---\\napiVersion: opentelemetry.io/v1alpha1\\nkind: OpenTelemetryCollector\\nmetadata:\\n  name: my-collector-amp\\n  namespace: aws-otel-eks\\nspec:\\n  mode: deployment\\n  serviceAccount: adot-collector\\n  podAnnotations:\\n    prometheus.io/scrape: 'true'\\n    prometheus.io/port: '8888'\\n  config: |\\n    extensions:\\n      sigv4auth:\\n        region: <YOUR_AWS_REGION>\\n        service: \\\"aps\\\"\\n\\n    receivers:\\n      #\\n      # Scrape configuration for the Prometheus Receiver\\n      # This is the same configuration used when Prometheus is installed using the community Helm chart\\n      #\\n      prometheus:\\n        config:\\n          global:\\n            scrape_interval: 15s\\n            scrape_timeout: 10s\\n\\n          scrape_configs:\\n          - job_name: 'collector-scraping'\\n            kubernetes_sd_configs:\\n            - role: pod\\n\\n    processors:\\n      batch/metrics:\\n        timeout: 60s\\n\\n    exporters:\\n      prometheusremotewrite:\\n        endpoint: \\\"<YOUR_REMOTE_WRITE_ENDPOINT>\\\"\\n        auth:\\n          authenticator: sigv4auth\\n\\n    service:\\n      extensions: [sigv4auth]\\n      pipelines:\\n        metrics:\\n          receivers: [prometheus]\\n          processors: [batch/metrics]\\n          exporters: [prometheusremotewrite]\\n\\n---\\napiVersion: rbac.authorization.k8s.io/v1\\nkind: ClusterRole\\nmetadata:\\n  name: otel-prometheus-role\\n  namespace: aws-otel-eks\\nrules:\\n  - apiGroups:\\n      - \\\"\\\"\\n    resources:\\n      - nodes\\n      - nodes/proxy\\n      - services\\n      - endpoints\\n      - pods\\n    verbs:\\n      - get\\n      - list\\n      - watch\\n  - apiGroups:\\n      - extensions\\n    resources:\\n      - ingresses\\n    verbs:\\n      - get\\n      - list\\n      - watch\\n  - nonResourceURLs:\\n      - /metrics\\n    verbs:\\n      - get\\n\\n---\\napiVersion: rbac.authorization.k8s.io/v1\\nkind: ClusterRoleBinding\\nmetadata:\\n  name: otel-prometheus-role-binding\\nroleRef:\\n  apiGroup: rbac.authorization.k8s.io\\n  kind: ClusterRole\\n  name: otel-prometheus-role\\nsubjects:\\n  - kind: ServiceAccount\\n    name: adot-collector\\n    namespace: aws-otel-eks\\n\"))), mdx(\"p\", null, \"To deploy your collector, make sure to replace \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"<YOUR_REMOTE_WRITE_ENDPOINT>\"), \" in the prometheusremoterwite exporter config, and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"<YOUR_AWS_REGION>\"), \" in the sigv4auth extension config, as per your own target environment and execute the following command :\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"kubectl apply -f collector-config-amp.yaml\\n\")), mdx(\"p\", null, \"Verify that the metrics are successfully collected by the ADOT Collector and exported to the intended destinations. Run the following command to check if Amazon Managed Prometheus received the Prometheus metrics data scrape_duration_seconds.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"awscurl --service=\\\"aps\\\" --region=\\\"<YOUR_AWS_REGION>\\\" \\\\\\n\\\"https://aps-workspaces.<YOUR_AWS_REGION>.amazonaws.com/workspaces/<YOUR_AMP_WORKSPACE_ID>/api/v1/query?query=scrape_duration_seconds\\\"\\n\")), mdx(\"p\", null, \"Make sure to replace the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"<YOUR_AWS_REGION>\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"<YOUR_AMP_WORKSPACE_ID>\"), \" fields for both queries. Your output should look something like this:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"{\\\"status\\\":\\\"success\\\",\\\"data\\\":{\\\"resultType\\\":\\\"vector\\\",\\\"result\\\":[{\\\"metric\\\":{\\\"EKS_Container\\\":\\\"cert-manager\\\",\\\"EKS_Namespace\\\":\\\"cert-manager\\\",\\\"EKS_PodName\\\":\\\"cert-manager-858bf78c95-qvq2j\\\",\\\"__name__\\\":\\\"scrape_duration_seconds\\\",\\\"app\\\":\\\"cert-manager\\\",\\\"app_kubernetes_io_component\\\":\\\"controller\\\",\\\"app_kubernetes_io_instance\\\":\\\"cert-manager\\\",\\\"app_kubernetes_io_name\\\":\\\"cert-manager\\\",\\\"instance\\\":\\\"192.168.41.17:9402\\\",\\\"job\\\":\\\"storefront\\\",\\\"pod_template_hash\\\":\\\"858bf78c95\\\"},\\\"value\\\":[1636159948.136,\\\"0.001410662\\\"]}]}}\\n\")), mdx(\"p\", null, \"This image below represents the metrics collected from Prometheus sample app and exported to monitoring destination AMP and visualized in AMG:\"), mdx(\"img\", {\n    src: resultaddonexample,\n    alt: \"End to end sample setup\",\n    style: {\n      \"margin\": \"20px 0\"\n    }\n  }), mdx(\"p\", null, \"To ensure a smooth migration process from Prometheus to OpenTelemetry, it is essential to leverage the official \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://opentelemetry.io/docs/\"\n  }, \"OpenTelemetry documentation\"), \". Detailed technical documentation is available on the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws-otel.github.io/\"\n  }, \"ADOT Website\"), \", and you can \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws-otel.github.io/download\"\n  }, \"download the distribution\"), \" from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/aws-observability/aws-otel-collector/releases/\"\n  }, \"GitHub\"), \". You can also download the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://gallery.ecr.aws/aws-observability/aws-otel-collector\"\n  }, \"latest ADOT collector image\"), \" from the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws.amazon.com/ecr/\"\n  }, \"Amazon Elastic Container Registry (ECR)\"), \" Public Gallery.\"), mdx(\"p\", null, \"To learn more about how to use ADOT to collect data for your observability solution, check out the hands-on \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://catalog.workshops.aws/observability/en-US/intro\"\n  }, \"AWS Observability workshop\"), \" and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://aws-observability.github.io/terraform-aws-observability-accelerator/\"\n  }, \"AWS Observability Accelerator\"), \". Please file an \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/aws-observability/aws-otel-community/issues\"\n  }, \"issue\"), \" if you have questions or feedback on migrating your Prometheus setup to OpenTelemetry.\"));\n}\n;\nMDXContent.isMDXComponent = true;","headings":[{"depth":2,"value":"Introduction"},{"depth":2,"value":"Steps To Migrate"},{"depth":3,"value":"Prometheus setup"},{"depth":3,"value":"ADOT Collector setup"},{"depth":3,"value":"Design migration strategy"},{"depth":3,"value":"Monitor and optimize"},{"depth":2,"value":"Demo"},{"depth":3,"value":"Prerequisites"},{"depth":3,"value":"Setup"},{"depth":3,"value":"Deploy sample application"}]}},"pageContext":{"slug":"/docs/migration-to-adot/","repositoryEditUrl":"https://github.com/rocketseat/gatsby-themes/tree/main/examples/gatsby-theme-docs/src/docs/migration-to-adot.mdx","repositoryProvider":"GitHub"}},
    "staticQueryHashes": ["2501019404","973074209"]}